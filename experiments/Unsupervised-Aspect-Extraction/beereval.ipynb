{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ds = pd.read_csv('../../beer_data/beer_ds.csv')\n",
    "\n",
    "from ast import literal_eval as make_tuple\n",
    "ds['bits'] = ds['bits'].map(lambda s : make_tuple(s))\n",
    "\n",
    "aspect_columns = sorted(['review/appearance', 'review/taste', 'review/aroma', 'review/palate'])\n",
    "\n",
    "train_idxs, val_idxs = train_test_split(ds.index, stratify=ds['bits'], train_size=0.9, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = val_idxs\n",
    "H = {}\n",
    "for i in range(4) :\n",
    "    H[str(i)] = np.zeros((len(idxs), len(idxs)))\n",
    "    a0 = set(ds[ds[aspect_columns[i]] == 0].index) & set(idxs)\n",
    "    a1 = set(ds[ds[aspect_columns[i]] == 1].index) & set(idxs)\n",
    "    a0 = list(map(lambda s : list(idxs).index(s), a0))\n",
    "    a1 = list(map(lambda s : list(idxs).index(s), a1))\n",
    "    for j in a0 :\n",
    "        H[str(i)][j, a0] = 1\n",
    "    for j in a1 :\n",
    "        H[str(i)][j, a1] = 1\n",
    "\n",
    "    H[str(i)][np.arange(len(idxs)), np.arange(len(idxs))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "lang_1 = pickle.load(open('data_beer_lemm_90K_sep.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = lang_1['training']\n",
    "lang_1['vocab_size'] = len(lang_1['word2idx'])\n",
    "lang_1['word_dim'] = 200\n",
    "import torch\n",
    "import model\n",
    "mod = model.Model(lang_1=lang_1, num_aspect=20)\n",
    "mod.load_values('results/model_SatFeb1716:51:402018_beer_90K_lemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = []\n",
    "for i, doc in enumerate(lang_1['training']) :\n",
    "    if i in val_idxs :\n",
    "        new_sent = [sent for sent in doc if len(sent) > 0]\n",
    "        mod.train_batch(new_sent, [new_sent], update=False)\n",
    "        embeds.append(mod.z_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(embeds) :\n",
    "    embeds[i] = e.mean(dim=0).data.cpu().numpy()\n",
    "e = np.array(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "e = normalize(e, 'l2')\n",
    "scores = np.dot(e, e.T)\n",
    "nb_studies = len(val_idxs)\n",
    "scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5001488836063909\n",
      "1 0.499976687348609\n",
      "2 0.4998983137428305\n",
      "3 0.499860037330679\n"
     ]
    }
   ],
   "source": [
    "aucs = [0] * len(val_idxs)\n",
    "aspects = [str(i) for i in range(4)]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "for aspect_j in aspects :\n",
    "    for i in range(len(val_idxs)) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print(aspect_j, np.mean(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
