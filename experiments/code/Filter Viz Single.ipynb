{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models  import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "import cPickle\n",
    "import sys\n",
    "sys.path.insert(0, '../../preprocess')\n",
    "import vectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gcnn import GCNN\n",
    "aspects = ['population', 'intervention', 'outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = cPickle.load(open('../data/vectorizers/allfields_with_embedding_5000.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = vec.index\n",
    "C = {'inputs' : ['abstract', 'population', 'intervention', 'outcome']}\n",
    "for input in C['inputs'] :\n",
    "    input_range = index[input]\n",
    "    C[input] = vec.X[input_range[0]:input_range[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5bccf4804e7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = load_model('../store/weights/single_setup/TueNov1423:49:292017/loss.h5', \n\u001b[0;32m----> 2\u001b[0;31m                    custom_objects={'contrastive_loss' : lambda a,b : a, 'GCNN' : GCNN})\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#results_folder = '../store/results/single_message_ThuOct1919:10:492017/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0moptimizer_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             optimizer_weight_names = [n.decode('utf8') for n in\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    958\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    959\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    961\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                 \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/keras/optimizers.pyc\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mm_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mv_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                          as_ref=False):\n\u001b[1;32m    120\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    362\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "model = load_model('../store/weights/single_setup/WedNov1500:02:112017/loss.h5', \n",
    "                   custom_objects={'contrastive_loss' : lambda a,b : a, 'GCNN' : GCNN})\n",
    "#results_folder = '../store/results/single_message_ThuOct1919:10:492017/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c1 = {}\n",
    "for aspect in aspects :\n",
    "    model_c1[aspect] = K.function(model.get_layer('pool_'+aspect[0].upper()).inputs, \n",
    "                          [model.get_layer('pool_'+aspect[0].upper()).layers[2].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters_pico = {}\n",
    "sample_length = 5000\n",
    "sample = np.random.choice(C['abstract'].shape[0], sample_length, replace=False)\n",
    "for input in C['inputs'] :\n",
    "    for aspect in aspects :\n",
    "        filters_pico[(aspect, input)] = model_c1[aspect]([C[input][sample]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87666666666666671"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(filters_pico[('population', 'intervention')].sum(axis=1).sum(axis=0) > 0).sum()/300.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intervention', 'abstract') 15\n",
      "('intervention', 'intervention') 8\n",
      "('intervention', 'outcome') 1\n",
      "('intervention', 'population') 2\n",
      "('outcome', 'abstract') 13\n",
      "('outcome', 'intervention') 1\n",
      "('outcome', 'outcome') 5\n",
      "('outcome', 'population') 2\n",
      "('population', 'abstract') 12\n",
      "('population', 'intervention') 1\n",
      "('population', 'outcome') 1\n",
      "('population', 'population') 7\n"
     ]
    }
   ],
   "source": [
    "nb_act = {k:(v > 0).sum()/sample_length for k,v in filters_pico.items()}\n",
    "for key in sorted(nb_act.keys()) :\n",
    "    print key,nb_act[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activated_words = {}\n",
    "for aspect in aspects :\n",
    "    filters = filters_pico[(aspect, 'abstract')]\n",
    "    word_activations = np.zeros((vec.vocab_size, filters.shape[2]))\n",
    "    for i in range(filters.shape[2]) :\n",
    "        filter_i = filters[:,:,i]\n",
    "        word2filter = np.dstack((C['abstract'][sample], filter_i))\n",
    "        filter_w2f = word2filter[word2filter[:,:,1] > 0.0]\n",
    "        for word in filter_w2f :\n",
    "            word_activations[int(word[0]), i] = word[1]\n",
    "    activated_words[aspect] = word_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>intervention</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>african</td>\n",
       "      <td>atorvastatin</td>\n",
       "      <td>adhesion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>african-american</td>\n",
       "      <td>atropine</td>\n",
       "      <td>arteriosus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>antiretroviral</td>\n",
       "      <td>bleomycin</td>\n",
       "      <td>auc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ards</td>\n",
       "      <td>cimetidine</td>\n",
       "      <td>bacteriological</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asian</td>\n",
       "      <td>cpm</td>\n",
       "      <td>bradycardia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bph</td>\n",
       "      <td>epa</td>\n",
       "      <td>cgi-i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bulimia</td>\n",
       "      <td>fractions</td>\n",
       "      <td>colonization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cirrhotic</td>\n",
       "      <td>glutamine</td>\n",
       "      <td>cure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fertilization</td>\n",
       "      <td>hctz</td>\n",
       "      <td>diarrhea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fibromyalgia</td>\n",
       "      <td>hes</td>\n",
       "      <td>erythema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>geographic</td>\n",
       "      <td>ino</td>\n",
       "      <td>esr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>haemodialysis</td>\n",
       "      <td>intramuscularly</td>\n",
       "      <td>exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hamd</td>\n",
       "      <td>ma</td>\n",
       "      <td>ham-d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>headaches</td>\n",
       "      <td>meals</td>\n",
       "      <td>healing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hemodialysis</td>\n",
       "      <td>midazolam</td>\n",
       "      <td>hemodialysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>immunodeficiency</td>\n",
       "      <td>n-acetylcysteine</td>\n",
       "      <td>hemodynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>impacted</td>\n",
       "      <td>nacl</td>\n",
       "      <td>hypotension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>infertility</td>\n",
       "      <td>nitrous</td>\n",
       "      <td>injuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>leukaemia</td>\n",
       "      <td>noninvasive</td>\n",
       "      <td>marginal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>leukemia</td>\n",
       "      <td>orlistat</td>\n",
       "      <td>microbiological</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>low-income</td>\n",
       "      <td>outreach</td>\n",
       "      <td>nec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lymphoma</td>\n",
       "      <td>oxybutynin</td>\n",
       "      <td>non-fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>medicaid</td>\n",
       "      <td>pep</td>\n",
       "      <td>palsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>metastatic</td>\n",
       "      <td>policy</td>\n",
       "      <td>parasitological</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>metropolitan</td>\n",
       "      <td>polyethylene</td>\n",
       "      <td>parathyroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>migraine</td>\n",
       "      <td>porcine</td>\n",
       "      <td>parkinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nervosa</td>\n",
       "      <td>reminder</td>\n",
       "      <td>pcr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>osteoarthritis</td>\n",
       "      <td>rfa</td>\n",
       "      <td>pi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>parturients</td>\n",
       "      <td>ringer</td>\n",
       "      <td>preeclampsia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pertussis</td>\n",
       "      <td>rocuronium</td>\n",
       "      <td>rebleeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>premenopausal</td>\n",
       "      <td>s.c.</td>\n",
       "      <td>restenosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rosacea</td>\n",
       "      <td>sheet</td>\n",
       "      <td>seroconversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sah</td>\n",
       "      <td>sildenafil</td>\n",
       "      <td>spotting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>singleton</td>\n",
       "      <td>slit</td>\n",
       "      <td>staining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>subfertility</td>\n",
       "      <td>stretching</td>\n",
       "      <td>staphylococcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sulphonylurea</td>\n",
       "      <td>taught</td>\n",
       "      <td>tomography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>throat</td>\n",
       "      <td>titanium</td>\n",
       "      <td>tracheal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>tolterodine</td>\n",
       "      <td>transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>urban</td>\n",
       "      <td>tranexamic</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>vitiligo</td>\n",
       "      <td>triamcinolone</td>\n",
       "      <td>virological</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          population      intervention          outcome\n",
       "0            african      atorvastatin         adhesion\n",
       "1   african-american          atropine       arteriosus\n",
       "2     antiretroviral         bleomycin              auc\n",
       "3               ards        cimetidine  bacteriological\n",
       "4              asian               cpm      bradycardia\n",
       "5                bph               epa            cgi-i\n",
       "6            bulimia         fractions     colonization\n",
       "7          cirrhotic         glutamine             cure\n",
       "8      fertilization              hctz         diarrhea\n",
       "9       fibromyalgia               hes         erythema\n",
       "10        geographic               ino              esr\n",
       "11     haemodialysis   intramuscularly        exclusive\n",
       "12              hamd                ma            ham-d\n",
       "13         headaches             meals          healing\n",
       "14      hemodialysis         midazolam     hemodialysis\n",
       "15  immunodeficiency  n-acetylcysteine      hemodynamic\n",
       "16          impacted              nacl      hypotension\n",
       "17       infertility           nitrous         injuries\n",
       "18         leukaemia       noninvasive         marginal\n",
       "19          leukemia          orlistat  microbiological\n",
       "20        low-income          outreach              nec\n",
       "21          lymphoma        oxybutynin        non-fatal\n",
       "22          medicaid               pep            palsy\n",
       "23        metastatic            policy  parasitological\n",
       "24      metropolitan      polyethylene      parathyroid\n",
       "25          migraine           porcine        parkinson\n",
       "26           nervosa          reminder              pcr\n",
       "27    osteoarthritis               rfa               pi\n",
       "28       parturients            ringer     preeclampsia\n",
       "29         pertussis        rocuronium       rebleeding\n",
       "30     premenopausal              s.c.       restenosis\n",
       "31           rosacea             sheet   seroconversion\n",
       "32               sah        sildenafil         spotting\n",
       "33         singleton              slit         staining\n",
       "34      subfertility        stretching   staphylococcus\n",
       "35     sulphonylurea            taught       tomography\n",
       "36            throat          titanium         tracheal\n",
       "37      tuberculosis       tolterodine     transmission\n",
       "38             urban        tranexamic       validation\n",
       "39          vitiligo     triamcinolone      virological"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df = pd.DataFrame()\n",
    "top_words_size = 40\n",
    "for aspect in aspects :\n",
    "    popwords = activated_words[aspect].sum(axis=1)\n",
    "    sorted_idx = np.argsort(popwords)\n",
    "    top_words = sorted_idx[-top_words_size:]\n",
    "    top_words = pd.Series([v for k, v in vec.idx2word.items() if k in top_words])\n",
    "    top_words_df[aspect] = top_words\n",
    "top_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluating Filters on Cohen Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/files/test_cohen_dedup.csv')\n",
    "cohenvec = cPickle.load(open('../data/vectorizers/cohendata_dedup_5000.p', 'rb'))\n",
    "cohenvec = cPickle.load(open('../data/vectorizers/decision_aids_vec_5000.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_aspect = {}\n",
    "for aspect in aspects :\n",
    "    filter_aspect[aspect] = model_c1[aspect]([cohenvec.X])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention': array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32),\n",
       " 'outcome': array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32),\n",
       " 'population': array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ..., \n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ..., \n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ..., \n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.80012941,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        ..., \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ..., \n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ..., \n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ..., \n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]]], dtype=float32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activated_words_cohen = {}\n",
    "for aspect in aspects :\n",
    "    filters = filter_aspect[aspect]\n",
    "    word_activations = np.zeros((cohenvec.vocab_size, filters.shape[2]))\n",
    "    for i in range(filters.shape[2]) :\n",
    "        filter_i = filters[:,:,i]\n",
    "        word2filter = np.dstack((cohenvec.X, filter_i))\n",
    "        filter_w2f = word2filter[word2filter[:,:,1] > 0.0]\n",
    "        for word in filter_w2f :\n",
    "            word_activations[int(word[0]), i] = word[1]\n",
    "    activated_words_cohen[aspect] = word_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>intervention</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>adjuvant</td>\n",
       "      <td>adherence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>against</td>\n",
       "      <td>aspirin</td>\n",
       "      <td>antigen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allowing</td>\n",
       "      <td>behaviors</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anomalies</td>\n",
       "      <td>booklet</td>\n",
       "      <td>atrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>antigen</td>\n",
       "      <td>chemotherapy</td>\n",
       "      <td>attacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>behaviors</td>\n",
       "      <td>computer</td>\n",
       "      <td>attitudes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>canada</td>\n",
       "      <td>consultations</td>\n",
       "      <td>behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cancer</td>\n",
       "      <td>counseling</td>\n",
       "      <td>behaviors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cancers</td>\n",
       "      <td>decisions</td>\n",
       "      <td>burden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cesarean</td>\n",
       "      <td>discussion</td>\n",
       "      <td>cesarean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>colon</td>\n",
       "      <td>education</td>\n",
       "      <td>consultations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>colorectal</td>\n",
       "      <td>educational</td>\n",
       "      <td>decisions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>comorbidity</td>\n",
       "      <td>electronic</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>develop</td>\n",
       "      <td>encouraged</td>\n",
       "      <td>detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>evidence-based</td>\n",
       "      <td>evidence-based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>glycemic</td>\n",
       "      <td>feedback</td>\n",
       "      <td>fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>inpatients</td>\n",
       "      <td>fibrillation</td>\n",
       "      <td>glycemic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>interviewed</td>\n",
       "      <td>genetic</td>\n",
       "      <td>growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>male</td>\n",
       "      <td>guided</td>\n",
       "      <td>knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>males</td>\n",
       "      <td>guidelines</td>\n",
       "      <td>mammography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>measuring</td>\n",
       "      <td>implemented</td>\n",
       "      <td>maternal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mellitus</td>\n",
       "      <td>individualized</td>\n",
       "      <td>measuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>menopause</td>\n",
       "      <td>interactive</td>\n",
       "      <td>mortality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>north</td>\n",
       "      <td>package</td>\n",
       "      <td>perceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>outpatients</td>\n",
       "      <td>program</td>\n",
       "      <td>persistence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>physicians</td>\n",
       "      <td>programme</td>\n",
       "      <td>post-intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>postmenopausal</td>\n",
       "      <td>provision</td>\n",
       "      <td>prenatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>practitioners</td>\n",
       "      <td>questions</td>\n",
       "      <td>probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pregnant</td>\n",
       "      <td>reconstruction</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>prenatal</td>\n",
       "      <td>resources</td>\n",
       "      <td>rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>presented</td>\n",
       "      <td>sessions</td>\n",
       "      <td>requires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>process</td>\n",
       "      <td>solution</td>\n",
       "      <td>retention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>provision</td>\n",
       "      <td>statin</td>\n",
       "      <td>satisfaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>public</td>\n",
       "      <td>tailored</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>recommend</td>\n",
       "      <td>tamoxifen</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>reconstruction</td>\n",
       "      <td>technique</td>\n",
       "      <td>self-efficacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>requires</td>\n",
       "      <td>training</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>socioeconomic</td>\n",
       "      <td>video</td>\n",
       "      <td>validated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>urban</td>\n",
       "      <td>warfarin</td>\n",
       "      <td>version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>women</td>\n",
       "      <td>written</td>\n",
       "      <td>well-being</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        population    intervention            outcome\n",
       "0         accuracy        adjuvant          adherence\n",
       "1          against         aspirin            antigen\n",
       "2         allowing       behaviors            anxiety\n",
       "3        anomalies         booklet             atrial\n",
       "4          antigen    chemotherapy            attacks\n",
       "5        behaviors        computer          attitudes\n",
       "6           canada   consultations           behavior\n",
       "7           cancer      counseling          behaviors\n",
       "8          cancers       decisions             burden\n",
       "9         cesarean      discussion           cesarean\n",
       "10           colon       education      consultations\n",
       "11      colorectal     educational          decisions\n",
       "12     comorbidity      electronic         depression\n",
       "13         develop      encouraged          detection\n",
       "14        diabetes  evidence-based     evidence-based\n",
       "15        glycemic        feedback       fibrillation\n",
       "16      inpatients    fibrillation           glycemic\n",
       "17     interviewed         genetic             growth\n",
       "18            male          guided          knowledge\n",
       "19           males      guidelines        mammography\n",
       "20       measuring     implemented           maternal\n",
       "21        mellitus  individualized          measuring\n",
       "22       menopause     interactive          mortality\n",
       "23           north         package        perceptions\n",
       "24     outpatients         program        persistence\n",
       "25      physicians       programme  post-intervention\n",
       "26  postmenopausal       provision           prenatal\n",
       "27   practitioners       questions        probability\n",
       "28        pregnant  reconstruction            quality\n",
       "29        prenatal       resources             rating\n",
       "30       presented        sessions           requires\n",
       "31         process        solution          retention\n",
       "32       provision          statin       satisfaction\n",
       "33          public        tailored          satisfied\n",
       "34       recommend       tamoxifen              scale\n",
       "35  reconstruction       technique      self-efficacy\n",
       "36        requires        training               task\n",
       "37   socioeconomic           video          validated\n",
       "38           urban        warfarin            version\n",
       "39           women         written         well-being"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df_cohen = pd.DataFrame()\n",
    "top_words_size = 40\n",
    "for aspect in aspects :\n",
    "    popwords = activated_words_cohen[aspect].sum(axis=1)\n",
    "    sorted_idx = np.argsort(popwords)\n",
    "    top_words = sorted_idx[-top_words_size:]\n",
    "    top_words = pd.Series([v for k, v in cohenvec.idx2word.items() if k in top_words])\n",
    "    top_words_df_cohen[aspect] = top_words\n",
    "top_words_df_cohen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summed = {}\n",
    "for aspect in aspects :\n",
    "    summed[aspect] = filter_aspect[aspect].sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_words = map(lambda s : [cohenvec.idx2word[w] for w in s], cohenvec.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipped = zip(X_words, summed['population'], summed['intervention'], summed['outcome'])\n",
    "total_vals = []\n",
    "for x,p,i,o in zipped :\n",
    "    total_vals.append(zip(x,p,i,o))\n",
    "    \n",
    "for abst in total_vals :\n",
    "    for sent in abst :\n",
    "        if sent[0] != '[0]' :\n",
    "            if sent[1] > 0 and sent[2] > 0 and sent[3] > 0:\n",
    "                print \"\\033[1;33;48m \"+sent[0],\n",
    "            elif sent[1] > 0 :\n",
    "                print \"\\033[1;31;48m \"+sent[0], \n",
    "            elif sent[2] > 0 :\n",
    "                print \"\\033[1;32;48m \"+sent[0],\n",
    "            elif sent[3] > 0 :\n",
    "                print \"\\033[1;34;48m \"+sent[0],\n",
    "            else :\n",
    "                print \"\\033[0;30;48m \"+sent[0],\n",
    "        \n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_ipython().system('cp \"Filter Viz Single.ipynb\" '+results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
