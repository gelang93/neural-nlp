{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import sys\n",
    "sys.path.insert(0, '../../preprocess')\n",
    "import vectorizer\n",
    "\n",
    "vec = cPickle.load(open('../../preprocess/allfields_with_embedding_19995.p', 'rb'))\n",
    "cohen_vec = cPickle.load(open('../../preprocess/cohendata_dedup_19995.p'))\n",
    "#da_vec = cPickle.load(open('../data/vectorizers/decision_aids_vec_5000.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/files/test_cohen_dedup.csv')\n",
    "\n",
    "nb_studies = len(df)\n",
    "H = np.zeros((nb_studies, nb_studies))\n",
    "\n",
    "cdnos = list(set(df.cdno))\n",
    "for i in range(nb_studies) :\n",
    "    H[i, df[df['cdno'] == df['cdno'][i]].index] = 1\n",
    "    \n",
    "H[np.arange(nb_studies), np.arange(nb_studies)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = vec.index['abstract']\n",
    "vec.X = vec.X[index[0]:index[1]]\n",
    "train_X = vec.X\n",
    "train_X = map(lambda s : [vec.idx2word[t] for t in s if t > 1], train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = cohen_vec.X\n",
    "test_X = map(lambda s : [vec.idx2word[t] for t in s if t > 1], test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False)\n",
    "train_TF = tfidf.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_TF = tfidf.transform(test_X)\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "# embedds_n = normalize(np.array(test_TF.todense()), 'l2')\n",
    "# scores = np.dot(embedds_n, embedds_n.T)\n",
    "scores = cosine_similarity(test_TF)\n",
    "scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790149201688\n",
      "                                          0\n",
      "ACEInhibitors_processed            0.809715\n",
      "ADHD_processed                     0.896114\n",
      "Antihistamines_processed           0.810739\n",
      "AtypicalAntipsychotics_processed   0.746003\n",
      "BetaBlockers_processed             0.672498\n",
      "CalciumChannelBlockers_processed   0.665070\n",
      "Estrogens_processed                0.874923\n",
      "NSAIDS_processed                   0.848748\n",
      "Opiods_processed                   0.812200\n",
      "OralHypoglycemics_processed        0.786787\n",
      "ProtonPumpInhibitors_processed     0.809734\n",
      "SkeletalMuscleRelaxants_processed  0.596118\n",
      "Statins_processed                  0.788765\n",
      "Triptans_processed                 0.924097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.DataFrame(pd.Series(rocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(tokenizer=lambda i:i, lowercase=False)\n",
    "train_C = count.fit_transform(train_X)\n",
    "test_C = count.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.500310279253\n",
      "2 0.623527038882\n",
      "3 0.595615915264\n",
      "4 0.640634834028\n",
      "5 0.645601735729\n",
      "6 0.709009958285\n",
      "7 0.732644507308\n",
      "8 0.72626853244\n",
      "9 0.705524543521\n",
      "10 0.698009737851\n",
      "11 0.678954949293\n",
      "12 0.699571704167\n",
      "13 0.671752370888\n",
      "14 0.688309078422\n",
      "15 0.673867209576\n",
      "16 0.67140868851\n",
      "17 0.67585329223\n",
      "18 0.673402155916\n",
      "19 0.650542116128\n",
      "20 0.673550168861\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-475596ac97f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_top\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtest_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                         self._em_step(X[idx_slice, :], total_samples=n_samples,\n\u001b[0;32m--> 552\u001b[0;31m                                       batch_update=False, parallel=parallel)\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;31m# batch update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.pyc\u001b[0m in \u001b[0;36m_em_step\u001b[0;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m# E-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         _, suff_stats = self._e_step(X, cal_sstats=True, random_init=True,\n\u001b[0;32m--> 433\u001b[0;31m                                      parallel=parallel)\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;31m# M-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.pyc\u001b[0m in \u001b[0;36m_e_step\u001b[0;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[1;32m    384\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_change_tol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_sstats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                                               random_state)\n\u001b[0;32m--> 386\u001b[0;31m             for idx_slice in gen_even_slices(X.shape[0], n_jobs))\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;31m# merge result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.pyc\u001b[0m in \u001b[0;36m_update_doc_distribution\u001b[0;34m(X, exp_topic_word_distr, doc_topic_prior, max_iters, mean_change_tol, cal_sstats, random_state)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# The optimal phi_{dwk} is proportional to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# exp(E[log(theta_{dk})]) * exp(E[log(beta_{dw})]).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mnorm_phi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_doc_topic_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_topic_word_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             doc_topic_d = (exp_doc_topic_d *\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "best_mean = 0.0\n",
    "for n_top in range(1, 30) :\n",
    "    from sklearn.decomposition import LatentDirichletAllocation\n",
    "    lda = LatentDirichletAllocation(n_components=n_top)\n",
    "    train_lda = lda.fit_transform(train_C)\n",
    "    test_lda = lda.transform(test_C)\n",
    "    from sklearn.preprocessing import normalize\n",
    "    embedds_n = normalize(test_lda, 'l2')\n",
    "    scores = np.dot(embedds_n, embedds_n.T)\n",
    "    scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000\n",
    "    scores = np.array(scores)\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "    print n_top, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671772112187\n",
      "ACEInhibitors_processed              0.676719\n",
      "ADHD_processed                       0.768559\n",
      "Antihistamines_processed             0.642429\n",
      "AtypicalAntipsychotics_processed     0.703576\n",
      "BetaBlockers_processed               0.610434\n",
      "CalciumChannelBlockers_processed     0.629003\n",
      "Estrogens_processed                  0.600515\n",
      "NSAIDS_processed                     0.645389\n",
      "Opiods_processed                     0.735651\n",
      "OralHypoglycemics_processed          0.655636\n",
      "ProtonPumpInhibitors_processed       0.648496\n",
      "SkeletalMuscleRelaxants_processed    0.760118\n",
      "Statins_processed                    0.661097\n",
      "Triptans_processed                   0.764934\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#10 LDA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.Series(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663811713035\n",
      "                                          0\n",
      "ACEInhibitors_processed            0.570558\n",
      "ADHD_processed                     0.759764\n",
      "Antihistamines_processed           0.741349\n",
      "AtypicalAntipsychotics_processed   0.728739\n",
      "BetaBlockers_processed             0.596694\n",
      "CalciumChannelBlockers_processed   0.554335\n",
      "Estrogens_processed                0.596897\n",
      "NSAIDS_processed                   0.696318\n",
      "Opiods_processed                   0.635425\n",
      "OralHypoglycemics_processed        0.749142\n",
      "ProtonPumpInhibitors_processed     0.681956\n",
      "SkeletalMuscleRelaxants_processed  0.696130\n",
      "Statins_processed                  0.616788\n",
      "Triptans_processed                 0.719855\n"
     ]
    }
   ],
   "source": [
    "#LDA 20\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.DataFrame(pd.Series(rocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.649504072906\n",
      "                                          0\n",
      "ACEInhibitors_processed            0.626700\n",
      "ADHD_processed                     0.785363\n",
      "Antihistamines_processed           0.680185\n",
      "AtypicalAntipsychotics_processed   0.668366\n",
      "BetaBlockers_processed             0.614333\n",
      "CalciumChannelBlockers_processed   0.590059\n",
      "Estrogens_processed                0.582509\n",
      "NSAIDS_processed                   0.665451\n",
      "Opiods_processed                   0.605092\n",
      "OralHypoglycemics_processed        0.682193\n",
      "ProtonPumpInhibitors_processed     0.588913\n",
      "SkeletalMuscleRelaxants_processed  0.667337\n",
      "Statins_processed                  0.579902\n",
      "Triptans_processed                 0.786799\n"
     ]
    }
   ],
   "source": [
    "#LDA 30\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.DataFrame(pd.Series(rocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.688458054695\n",
      "                                          0\n",
      "ACEInhibitors_processed            0.733466\n",
      "ADHD_processed                     0.784954\n",
      "Antihistamines_processed           0.765961\n",
      "AtypicalAntipsychotics_processed   0.749551\n",
      "BetaBlockers_processed             0.561474\n",
      "CalciumChannelBlockers_processed   0.606236\n",
      "Estrogens_processed                0.595585\n",
      "NSAIDS_processed                   0.683773\n",
      "Opiods_processed                   0.726598\n",
      "OralHypoglycemics_processed        0.750995\n",
      "ProtonPumpInhibitors_processed     0.619063\n",
      "SkeletalMuscleRelaxants_processed  0.704253\n",
      "Statins_processed                  0.734470\n",
      "Triptans_processed                 0.745464\n"
     ]
    }
   ],
   "source": [
    "#LDA 5\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.DataFrame(pd.Series(rocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632397412097\n",
      "ACEInhibitors_processed              0.603385\n",
      "ADHD_processed                       0.792231\n",
      "Antihistamines_processed             0.725511\n",
      "AtypicalAntipsychotics_processed     0.729733\n",
      "BetaBlockers_processed               0.583911\n",
      "CalciumChannelBlockers_processed     0.534427\n",
      "Estrogens_processed                  0.549480\n",
      "NSAIDS_processed                     0.580660\n",
      "Opiods_processed                     0.614504\n",
      "OralHypoglycemics_processed          0.645920\n",
      "ProtonPumpInhibitors_processed       0.609919\n",
      "SkeletalMuscleRelaxants_processed    0.739308\n",
      "Statins_processed                    0.571358\n",
      "Triptans_processed                   0.678575\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#15 LDA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.Series(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.630408035104\n",
      "ACEInhibitors_processed              0.568822\n",
      "ADHD_processed                       0.745592\n",
      "Antihistamines_processed             0.648518\n",
      "AtypicalAntipsychotics_processed     0.631148\n",
      "BetaBlockers_processed               0.571659\n",
      "CalciumChannelBlockers_processed     0.535410\n",
      "Estrogens_processed                  0.554959\n",
      "NSAIDS_processed                     0.642947\n",
      "Opiods_processed                     0.615354\n",
      "OralHypoglycemics_processed          0.637152\n",
      "ProtonPumpInhibitors_processed       0.654760\n",
      "SkeletalMuscleRelaxants_processed    0.644289\n",
      "Statins_processed                    0.619789\n",
      "Triptans_processed                   0.752280\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#200 LDA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.Series(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.679566777892\n",
      "ACEInhibitors_processed              0.635814\n",
      "ADHD_processed                       0.820726\n",
      "Antihistamines_processed             0.638396\n",
      "AtypicalAntipsychotics_processed     0.842678\n",
      "BetaBlockers_processed               0.552658\n",
      "CalciumChannelBlockers_processed     0.589661\n",
      "Estrogens_processed                  0.680963\n",
      "NSAIDS_processed                     0.638793\n",
      "Opiods_processed                     0.593138\n",
      "OralHypoglycemics_processed          0.780940\n",
      "ProtonPumpInhibitors_processed       0.745649\n",
      "SkeletalMuscleRelaxants_processed    0.613927\n",
      "Statins_processed                    0.584975\n",
      "Triptans_processed                   0.685248\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#4 LDA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.Series(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.721504580854\n",
      "ACEInhibitors_processed              0.720642\n",
      "ADHD_processed                       0.800462\n",
      "Antihistamines_processed             0.700825\n",
      "AtypicalAntipsychotics_processed     0.725342\n",
      "BetaBlockers_processed               0.673189\n",
      "CalciumChannelBlockers_processed     0.651937\n",
      "Estrogens_processed                  0.643024\n",
      "NSAIDS_processed                     0.730007\n",
      "Opiods_processed                     0.699040\n",
      "OralHypoglycemics_processed          0.834619\n",
      "ProtonPumpInhibitors_processed       0.713034\n",
      "SkeletalMuscleRelaxants_processed    0.688588\n",
      "Statins_processed                    0.694711\n",
      "Triptans_processed                   0.790590\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#7 LDA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.Series(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.700454416337\n",
      "ACEInhibitors_processed              0.684900\n",
      "ADHD_processed                       0.820319\n",
      "Antihistamines_processed             0.779867\n",
      "AtypicalAntipsychotics_processed     0.750762\n",
      "BetaBlockers_processed               0.603489\n",
      "CalciumChannelBlockers_processed     0.587012\n",
      "Estrogens_processed                  0.630975\n",
      "NSAIDS_processed                     0.712957\n",
      "Opiods_processed                     0.646028\n",
      "OralHypoglycemics_processed          0.785506\n",
      "ProtonPumpInhibitors_processed       0.690359\n",
      "SkeletalMuscleRelaxants_processed    0.752506\n",
      "Statins_processed                    0.679658\n",
      "Triptans_processed                   0.760451\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#8 LDA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.Series(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.727974845604\n",
      "ACEInhibitors_processed              0.728741\n",
      "ADHD_processed                       0.789238\n",
      "Antihistamines_processed             0.782176\n",
      "AtypicalAntipsychotics_processed     0.700299\n",
      "BetaBlockers_processed               0.563129\n",
      "CalciumChannelBlockers_processed     0.621448\n",
      "Estrogens_processed                  0.668034\n",
      "NSAIDS_processed                     0.732668\n",
      "Opiods_processed                     0.753121\n",
      "OralHypoglycemics_processed          0.873091\n",
      "ProtonPumpInhibitors_processed       0.737209\n",
      "SkeletalMuscleRelaxants_processed    0.681528\n",
      "Statins_processed                    0.804431\n",
      "Triptans_processed                   0.814155\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#6 LDA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H[i], scores[i])\n",
    "print np.mean(aucs)\n",
    "rocs = {}\n",
    "for cd in cdnos :\n",
    "    idxs = df[df.cdno == cd].index\n",
    "    rocs[cd] = np.mean(np.array(aucs)[idxs])\n",
    "print pd.Series(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
