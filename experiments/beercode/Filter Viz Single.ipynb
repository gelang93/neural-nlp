{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models  import load_model\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import normalize\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(0, '../../preprocess')\n",
    "import vectorizer\n",
    "from colors import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "aspects = [str(i) for i in range(4)] #app, aroma, palate,taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../beer_data/beer_vec_ds_df10.p', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    vec = u.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ds = pd.read_csv('../../beer_data/beer_ds.csv')\n",
    "\n",
    "from ast import literal_eval as make_tuple\n",
    "ds['bits'] = ds['bits'].map(lambda s : make_tuple(s))\n",
    "\n",
    "aspect_columns = sorted(['review/appearance', 'review/taste', 'review/aroma', 'review/palate'])\n",
    "aspects = [str(i) for i in range(4)]\n",
    "\n",
    "train_idxs, val_idxs = train_test_split(ds.index, stratify=ds['bits'], train_size=0.9, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = val_idxs\n",
    "H = {}\n",
    "for i in range(4) :\n",
    "    H[str(i)] = np.zeros((len(idxs), len(idxs)))\n",
    "    a0 = set(ds[ds[aspect_columns[i]] == 0].index) & set(idxs)\n",
    "    a1 = set(ds[ds[aspect_columns[i]] == 1].index) & set(idxs)\n",
    "    a0 = list(map(lambda s : list(idxs).index(s), a0))\n",
    "    a1 = list(map(lambda s : list(idxs).index(s), a1))\n",
    "    for j in a0 :\n",
    "        H[str(i)][j, a0] = 1\n",
    "    for j in a1 :\n",
    "        H[str(i)][j, a1] = 1\n",
    "\n",
    "    H[str(i)][np.arange(len(idxs)), np.arange(len(idxs))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('../store/weights/beer/Gated2CNNModelSatJan615:09:332018/loss.h5', \n",
    "                   custom_objects={'contrastive_loss' : lambda a,b:b, '<lambda>' : lambda a,b : b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 316)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 316, 300)     4407000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 316, 1)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 316, 300)     0           embedding[0][0]                  \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 316, 200)     60200       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 316, 200)     200         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 316, 200)     0           p_re_lu_1[0][0]                  \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 316, 200)     120200      multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 316, 200)     200         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 316, 200)     0           p_re_lu_2[0][0]                  \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 316, 200)     0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 316, 200)     200200      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 316, 200)     200         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 316, 200)     0           p_re_lu_3[0][0]                  \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 316, 1)       1001        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 316, 200)     0           multiply_2[0][0]                 \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 316, 1)       0           conv1d_6[0][0]                   \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 316, 200)     0           add_2[0][0]                      \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 316, 200)     0           multiply_8[0][0]                 \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 200)          0           multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           multiply_7[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,789,201\n",
      "Trainable params: 4,789,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.get_layer('pred_0').get_layer('pool_0').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c1 = {}\n",
    "for aspect in aspects :\n",
    "    model_c1[aspect] = K.function(model.get_layer('pred_'+aspect).get_layer('pool_'+aspect).inputs, \n",
    "                          [model.get_layer('pred_'+aspect).get_layer('pool_'+aspect).layers[16].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vec.X[val_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_pico = {k:[] for k in aspects}\n",
    "#X = X[-2:]\n",
    "i, bs = 0, 100\n",
    "while i*bs < len(X):\n",
    "    for aspect in aspects :\n",
    "        val = model_c1[aspect]([X[i*bs:(i+1)*bs]])[0]#[:, :, :]\n",
    "        val = val.mean(axis=-1)\n",
    "        val = np.dstack((X[i*bs:(i+1)*bs], val))\n",
    "        filters_pico[aspect].append(val)\n",
    "    i+=1\n",
    "        \n",
    "for aspect in aspects :\n",
    "    filters_pico[aspect] = np.concatenate(filters_pico[aspect])\n",
    "#     for s in range(len(filters_pico[aspect])) :\n",
    "#         nz = sum([1 for i in filters_pico[aspect][s, :, 0] if i == 0])\n",
    "#         filters_pico[aspect][s, :nz, 1] = 1.\n",
    "#         filters_pico[aspect][s, :, 1] = np.convolve(filters_pico[aspect][s, :, 1], \n",
    "#                                                     [1./5 for _ in range(5)], mode='same')\n",
    "    #print filters_pico[aspect].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(int \"\")? (<ipython-input-18-4e125314b60b>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-4e125314b60b>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    print \"\"\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(int \"\")?\n"
     ]
    }
   ],
   "source": [
    "from random import random, randint\n",
    "for v in range(2) :\n",
    "    s = randint(0, len(filters_pico['3'])-1)\n",
    "\n",
    "    nz = sum([1 for i in filters_pico['3'][s, :, 0] if i == 0])\n",
    "    gate0 = filters_pico['0'][s, :, 1]\n",
    "    gate1 = filters_pico['1'][s, :, 1]\n",
    "    gate2 = filters_pico['2'][s, :, 1]\n",
    "    gate3 = filters_pico['3'][s, :, 1]\n",
    "\n",
    "    gate0[:nz] = 1.\n",
    "#     gate1[:nz] = 1.\n",
    "#     gate2[:nz] = 1.\n",
    "#     gate3[:nz] = 1.\n",
    "    gate0 = np.convolve(gate0, [1./5 for _ in range(5)], mode='same')\n",
    "    gate1 = np.convolve(gate1, [1./5 for _ in range(5)], mode='same')\n",
    "    gate2 = np.convolve(gate2, [1./5 for _ in range(5)], mode='same')\n",
    "    gate3 = np.convolve(gate3, [1./5 for _ in range(5)], mode='same')\n",
    "\n",
    "    gate0 = gate0 - gate0[nz:].mean(axis=0)\n",
    "    gate1 = gate1 - gate1[nz:].mean(axis=0)\n",
    "    gate2 = gate2 - gate2[nz:].mean(axis=0)\n",
    "    gate3 = gate3 - gate3[nz:].mean(axis=0)\n",
    "    \n",
    "    gate0 = gate0.clip(0, 1)\n",
    "    gate1 = gate1.clip(0, 1)\n",
    "    gate2 = gate2.clip(0, 1)\n",
    "    gate3 = gate3.clip(0, 1)\n",
    "\n",
    "    gate0 = (gate0 - gate0[nz:].min(axis=0))/ (gate0[nz:].max(axis=0) - gate0[nz:].min(axis=0))\n",
    "    gate1 = (gate1 - gate1[nz:].min(axis=0))/ (gate1[nz:].max(axis=0) - gate1[nz:].min(axis=0))\n",
    "    gate2 = (gate2 - gate2[nz:].min(axis=0))/ (gate2[nz:].max(axis=0) - gate2[nz:].min(axis=0))\n",
    "    gate3 = (gate3 - gate3[nz:].min(axis=0))/ (gate3[nz:].max(axis=0) - gate3[nz:].min(axis=0))\n",
    "\n",
    "\n",
    "\n",
    "    X_words = [vec.idx2word[int(i)] for i in filters_pico['3'][s, :, 0]]\n",
    "\n",
    "    for i, j in zip(X_words, gate0):\n",
    "        if i != '[0]':\n",
    "            print(color(i, bg=[int(255),int((1-j)*255), int((1-j)*255)]),)\n",
    "\n",
    "    print(\"\")\n",
    "    for i, j in zip(X_words, gate1) :\n",
    "        if i != '[0]':\n",
    "            print(color(i, bg=[int((1-j)*255), int(255), int((1-j)*255)]),)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    for i, j in zip(X_words, gate2) :\n",
    "        if i != '[0]':\n",
    "            print(color(i, bg=[int((1-j)*255), int((1-j)*255), int(255)]),)\n",
    "\n",
    "    print(\"\")\n",
    "    for i, j in zip(X_words, gate3) :\n",
    "        if i != '[0]':\n",
    "            print(color(i, bg=[int(255), int(255), int((1-j)*255)]),)\n",
    "            \n",
    "    print(\"\")\n",
    "    #print \"----------------------------------------------------------------------------------\"+str(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activated_words = {}\n",
    "for aspect in aspects :\n",
    "    filters = filters_pico[aspect]\n",
    "    word_activations = np.zeros((vec.vocab_size, 1))\n",
    "    word2filter = filters.reshape(-1, filters.shape[-1])\n",
    "    for word in word2filter :\n",
    "        word_activations[int(word[0]), 0] = word[1]\n",
    "    activated_words[aspect] = word_activations\n",
    "    \n",
    "joint = np.concatenate([activated_words[aspect] for aspect in aspects], axis=1)\n",
    "joint = joint[2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beans', 'bomb', 'christmas', 'complexity', 'disappointment', 'fingers', 'folks', 'good', 'holy', 'including', 'lemons', 'looked', 'metallic', 'mildly', 'nor', 'presentation', 'size', 'steady', 'time', 'waste']\n",
      "['brownish', 'complete', 'drain', 'edge', 'everything', 'gone', 'interesting', 'into', 'lacing', 'malty', 'mexican', 'o', 'pine', 'play', 'qqq', 'representation', 'skunk', 'slowly', 'terms', 'want']\n",
      "['amount', 'black', 'bomber', 'cut', 'd-', 'degrees', 'deserves', 'drink', 'english', 'excited', 'healthy', 'hops', 'mass', 'needs', 'nutty', 'previous', 'qqq', 'retains', 'thirst', 'worst']\n",
      "['available', 'away', 'burnt', 'cheers', 'd-', 'down', 'english', 'enjoyable', 'entirely', 'except', 'falls', 'flavor', 'great', 'imo', 'medium-bodied', 'pleasantly', 'porters', 'qqq', 'residual', 'warmth']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beans</td>\n",
       "      <td>brownish</td>\n",
       "      <td>amount</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bomb</td>\n",
       "      <td>complete</td>\n",
       "      <td>black</td>\n",
       "      <td>away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christmas</td>\n",
       "      <td>drain</td>\n",
       "      <td>bomber</td>\n",
       "      <td>burnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complexity</td>\n",
       "      <td>edge</td>\n",
       "      <td>cut</td>\n",
       "      <td>cheers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>everything</td>\n",
       "      <td>d-</td>\n",
       "      <td>d-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fingers</td>\n",
       "      <td>gone</td>\n",
       "      <td>degrees</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>folks</td>\n",
       "      <td>interesting</td>\n",
       "      <td>deserves</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good</td>\n",
       "      <td>into</td>\n",
       "      <td>drink</td>\n",
       "      <td>enjoyable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>holy</td>\n",
       "      <td>lacing</td>\n",
       "      <td>english</td>\n",
       "      <td>entirely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>including</td>\n",
       "      <td>malty</td>\n",
       "      <td>excited</td>\n",
       "      <td>except</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lemons</td>\n",
       "      <td>mexican</td>\n",
       "      <td>healthy</td>\n",
       "      <td>falls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>looked</td>\n",
       "      <td>o</td>\n",
       "      <td>hops</td>\n",
       "      <td>flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>metallic</td>\n",
       "      <td>pine</td>\n",
       "      <td>mass</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mildly</td>\n",
       "      <td>play</td>\n",
       "      <td>needs</td>\n",
       "      <td>imo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nor</td>\n",
       "      <td>qqq</td>\n",
       "      <td>nutty</td>\n",
       "      <td>medium-bodied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>presentation</td>\n",
       "      <td>representation</td>\n",
       "      <td>previous</td>\n",
       "      <td>pleasantly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>size</td>\n",
       "      <td>skunk</td>\n",
       "      <td>qqq</td>\n",
       "      <td>porters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>steady</td>\n",
       "      <td>slowly</td>\n",
       "      <td>retains</td>\n",
       "      <td>qqq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>time</td>\n",
       "      <td>terms</td>\n",
       "      <td>thirst</td>\n",
       "      <td>residual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>waste</td>\n",
       "      <td>want</td>\n",
       "      <td>worst</td>\n",
       "      <td>warmth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0               1         2              3\n",
       "0            beans        brownish    amount      available\n",
       "1             bomb        complete     black           away\n",
       "2        christmas           drain    bomber          burnt\n",
       "3       complexity            edge       cut         cheers\n",
       "4   disappointment      everything        d-             d-\n",
       "5          fingers            gone   degrees           down\n",
       "6            folks     interesting  deserves        english\n",
       "7             good            into     drink      enjoyable\n",
       "8             holy          lacing   english       entirely\n",
       "9        including           malty   excited         except\n",
       "10          lemons         mexican   healthy          falls\n",
       "11          looked               o      hops         flavor\n",
       "12        metallic            pine      mass          great\n",
       "13          mildly            play     needs            imo\n",
       "14             nor             qqq     nutty  medium-bodied\n",
       "15    presentation  representation  previous     pleasantly\n",
       "16            size           skunk       qqq        porters\n",
       "17          steady          slowly   retains            qqq\n",
       "18            time           terms    thirst       residual\n",
       "19           waste            want     worst         warmth"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df = pd.DataFrame()\n",
    "top_words_size = 20\n",
    "for aspect in aspects :\n",
    "    popwords = joint[:, int(aspect)]\n",
    "    sorted_idx = np.argsort(popwords)\n",
    "    top_words = sorted_idx[-top_words_size:]\n",
    "    print [str(v) for k, v in vec.idx2word.items() if k in top_words]\n",
    "    top_words = pd.Series([v for k, v in vec.idx2word.items() if k in top_words])\n",
    "    \n",
    "    top_words_df[aspect] = top_words\n",
    "top_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=\"Deep amber hue ,this brew is topped with a finger of off white head.\\\n",
    "Smell of dog hair, green olives, and slightly fruity.\\\n",
    "Taste of Belgian yeast, coriander, hard water and bready malt.\\\n",
    "Light body, with little carbonation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'deep', u'amber', u'hue', u',', u'this', u'brew', u'is', u'topped', u'with', u'a', u'finger', u'of', u'off', u'white', u'head', u'.', u'smell', u'of', u'dog', 1, u',', u'green', 1, u',', u'and', u'slightly', u'fruity', u'.', u'taste', u'of', u'belgian', u'yeast', u',', u'coriander', u',', u'hard', u'water', u'and', u'bready', u'malt', u'.', u'light', u'body', u',', u'with', u'little', u'carbonation', u'.']\n"
     ]
    }
   ],
   "source": [
    "t1 = [vec.word2idx[x.text.lower()] if x.text.lower() in vec.word2idx else 1 for x in nlp(unicode(s))]# if x in vec.word2idx]\n",
    "t2 = [0]*(305-len(t1)) + t1\n",
    "X = np.vstack((X[:-1], t2))\n",
    "print [x.text.lower() if x.text.lower() in vec.word2idx else 1 for x in nlp(unicode(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
