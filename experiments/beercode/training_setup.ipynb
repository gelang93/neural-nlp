{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import sys\n",
    "sys.path.insert(0, '../../preprocess')\n",
    "import vectorizer\n",
    "beer_data = cPickle.load(open('../../beer_data/beer_vec_ds_df10.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ds = pd.read_csv('../../beer_data/beer_ds.csv')\n",
    "\n",
    "from ast import literal_eval as make_tuple\n",
    "ds['bits'] = ds['bits'].map(lambda s : make_tuple(s))\n",
    "\n",
    "aspect_columns = sorted(['review/appearance', 'review/taste', 'review/aroma', 'review/palate'])\n",
    "aspects = [str(i) for i in range(4)]\n",
    "\n",
    "train_idxs, val_idxs = train_test_split(ds.index, stratify=ds['bits'], train_size=0.9, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = val_idxs\n",
    "H = {}\n",
    "labs = {}\n",
    "for i in range(4) :\n",
    "    H[str(i)] = np.zeros((len(idxs), len(idxs)))\n",
    "    a0 = set(ds[ds[aspect_columns[i]] == 0].index) & set(idxs)\n",
    "    a1 = set(ds[ds[aspect_columns[i]] == 1].index) & set(idxs)\n",
    "    a0 = map(lambda s : list(idxs).index(s), a0)\n",
    "    a1 = map(lambda s : list(idxs).index(s), a1)\n",
    "#     H[str(i)][np.ix_(a0, a0)] = 1\n",
    "#     H[str(i)][np.ix_(a1, a1)] = 1\n",
    "    \n",
    "    labs[str(i)] = np.array([0] * len(idxs))\n",
    "    labs[str(i)][a1] = 1\n",
    "    for j in a0 :\n",
    "        H[str(i)][j, a0] = 1\n",
    "    for j in a1 :\n",
    "        H[str(i)][j, a1] = 1\n",
    "\n",
    "    H[str(i)][np.arange(len(idxs)), np.arange(len(idxs))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NVDMModel import log_softmax, cross_ent_loss, sample_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('../store/weights/beer/Gated2CNNModelFriDec1517:16:522017dssm/loss.h5', \n",
    "                   custom_objects={'contrastive_loss' : lambda a,b:b})\n",
    "#model = load_model('../store/weights/beer/CountModelWedDec620:08:322017coutnfinal/loss.h5',\n",
    "#                   custom_objects={'contrastive_loss' : lambda a,b:b})\n",
    "# model = load_model('../store/weights/beer/NVDMModelThuDec1418:20:122017nvdm19K/loss.h5',\n",
    "#                   custom_objects={'contrastive_loss' : lambda a,b:b, 'log_softmax' : log_softmax,\n",
    "#                                  'cross_ent_loss' : cross_ent_loss, 'sample_norm' : sample_norm,\n",
    "#                                  '<lambda>' : lambda a,b : a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "model_c1 = {}\n",
    "for aspect in aspects :\n",
    "    model_c1[aspect] = K.function(\n",
    "                model.get_layer('pred_'+aspect).get_layer('pool_'+aspect).inputs + [K.learning_phase()], \n",
    "                model.get_layer('pred_'+aspect).get_layer('pool_'+aspect).outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s = beer_data.X[val_idxs]\n",
    "# X_tf = np.zeros((X_s.shape[0], beer_data.vocab_size))\n",
    "# for i in range(len(X_s)) :\n",
    "#     X_tf[i, X_s[i, :]] = 1.\n",
    "\n",
    "# X_tf = X_tf[:, 2:]\n",
    "# X_s = X_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = {}\n",
    "vecs = {k:[] for k in aspects}\n",
    "i, bs = 0, 100\n",
    "while i*bs < len(val_idxs):\n",
    "    for aspect in aspects :\n",
    "        result = model_c1[aspect]([X_s[i*bs:(i+1)*bs], 0])[0]\n",
    "        vecs[aspect].append(result)\n",
    "    i += 1\n",
    "\n",
    "for aspect in aspects :\n",
    "    embeds[aspect] = np.concatenate(vecs[aspect], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.911341239633\n",
      "0 1 0.890595569948\n",
      "0 2 0.885549865184\n",
      "0 3 0.87598861092\n",
      "1 0 0.899287180595\n",
      "1 1 0.92787190655\n",
      "1 2 0.914544674227\n",
      "1 3 0.918786200896\n",
      "2 0 0.900578244727\n",
      "2 1 0.923714328519\n",
      "2 2 0.928339228646\n",
      "2 3 0.925721081735\n",
      "3 0 0.898453918156\n",
      "3 1 0.945021579464\n",
      "3 2 0.945897428391\n",
      "3 3 0.957836092953\n"
     ]
    }
   ],
   "source": [
    "#Gated CNN\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "for aspect in aspects :\n",
    "    result = embeds[aspect]\n",
    "    result = normalize(result, 'l2')\n",
    "    scores = np.dot(result, result.T)\n",
    "    scores[np.arange(len(val_idxs)), np.arange(len(val_idxs))] = -1000\n",
    "    aucs = [0] * len(val_idxs)\n",
    "    for aspect_j in aspects :\n",
    "        for i in range(len(val_idxs)) :\n",
    "            aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "        print aspect, aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.854554973644\n",
      "0 1 0.820338060642\n",
      "0 2 0.81058697348\n",
      "0 3 0.797889746336\n",
      "1 0 0.870872248819\n",
      "1 1 0.894325436749\n",
      "1 2 0.880327258009\n",
      "1 3 0.880428469123\n",
      "2 0 0.87033988649\n",
      "2 1 0.890957378249\n",
      "2 2 0.896394404544\n",
      "2 3 0.890723541386\n",
      "3 0 0.860553813433\n",
      "3 1 0.907358169216\n",
      "3 2 0.911861669863\n",
      "3 3 0.923492443559\n"
     ]
    }
   ],
   "source": [
    "#Count \n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "for aspect in aspects :\n",
    "    result = embeds[aspect]\n",
    "    result = normalize(result, 'l2')\n",
    "    scores = np.dot(result, result.T)\n",
    "    scores[np.arange(len(val_idxs)), np.arange(len(val_idxs))] = -1000\n",
    "    aucs = [0] * len(val_idxs)\n",
    "    for aspect_j in aspects :\n",
    "        for i in range(len(val_idxs)) :\n",
    "            aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "        print aspect, aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.905304261335\n",
      "0 1 0.877807419298\n",
      "0 2 0.872206131665\n",
      "0 3 0.860663657542\n",
      "1 0 0.889331607361\n",
      "1 1 0.917559396232\n",
      "1 2 0.904842145736\n",
      "1 3 0.905617773251\n",
      "2 0 0.89315265191\n",
      "2 1 0.917335669635\n",
      "2 2 0.922035288076\n",
      "2 3 0.918620585403\n",
      "3 0 0.893972233173\n",
      "3 1 0.940251184915\n",
      "3 2 0.940928614247\n",
      "3 3 0.951425403999\n"
     ]
    }
   ],
   "source": [
    "#NVDM\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "for aspect in aspects :\n",
    "    result = embeds[aspect]\n",
    "    result = normalize(result, 'l2')\n",
    "    scores = np.dot(result, result.T)\n",
    "    scores[np.arange(len(val_idxs)), np.arange(len(val_idxs))] = -1000\n",
    "    aucs = [0] * len(val_idxs)\n",
    "    for aspect_j in aspects :\n",
    "        for i in range(len(val_idxs)) :\n",
    "            aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "        print aspect, aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 nan nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/sarthak/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.418999945239 0.599924764743\n",
      "0 2 0.398396384437 0.62942794504\n",
      "0 3 0.38229051475 0.653758284764\n",
      "1 0 0.328074756139 0.685847960222\n",
      "1 1 nan nan\n",
      "1 2 0.409582002789 0.593621923611\n",
      "1 3 0.406335125999 0.604767116258\n",
      "2 0 0.322878987074 0.695372910699\n",
      "2 1 0.456705868057 0.544314099743\n",
      "2 2 nan nan\n",
      "2 3 0.485365467409 0.51949291894\n",
      "3 0 0.231934426281 0.795875915478\n",
      "3 1 0.346276551121 0.663425388414\n",
      "3 2 0.334309001271 0.670527546249\n",
      "3 3 nan nan\n"
     ]
    }
   ],
   "source": [
    "#Gated CNN\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "for aspect in aspects :\n",
    "    result = embeds[aspect]\n",
    "    result = normalize(result, 'l2')\n",
    "    scores = np.dot(result, result.T)\n",
    "    scores[np.arange(len(val_idxs)), np.arange(len(val_idxs))] = -1000\n",
    "    \n",
    "    for aspect_j in aspects :\n",
    "        aucs_1, aucs_2 = [], []\n",
    "        diff = np.where(labs[aspect] != labs[aspect_j])[0]\n",
    "        for i, j in enumerate(diff) :\n",
    "            aucs_1.append(roc_auc_score(H[aspect_j][j], scores[j]))\n",
    "            aucs_2.append(roc_auc_score(H[aspect][j], scores[j]))\n",
    "\n",
    "        print aspect, aspect_j, np.mean(aucs_1), np.mean(aucs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.914870707499\n",
      "0 1 0.883242027296\n",
      "0 2 0.878992594595\n",
      "0 3 0.86796036685\n",
      "1 0 0.894897050529\n",
      "1 1 0.929701394345\n",
      "1 2 0.911345285882\n",
      "1 3 0.9134474411\n",
      "2 0 0.898631977632\n",
      "2 1 0.920803103162\n",
      "2 2 0.930926076498\n",
      "2 3 0.926525263047\n",
      "3 0 0.881059784896\n",
      "3 1 0.934046852142\n",
      "3 2 0.937719486865\n",
      "3 3 0.952891638474\n"
     ]
    }
   ],
   "source": [
    "#Gated CNN\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "for aspect in aspects :\n",
    "    result = embeds[aspect]\n",
    "    result = normalize(result, 'l2')\n",
    "    scores = np.dot(result, result.T)\n",
    "    scores[np.arange(len(val_idxs)), np.arange(len(val_idxs))] = -1000\n",
    "    aucs = [0] * len(val_idxs)\n",
    "    for aspect_j in aspects :\n",
    "        for i in range(len(val_idxs)) :\n",
    "            aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "        print aspect, aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.874847592559\n",
      "1 1 0.89250408592\n",
      "2 2 0.898233920927\n",
      "3 3 0.922284604947\n"
     ]
    }
   ],
   "source": [
    "#Gated CNN\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "for aspect in aspects :\n",
    "    result = embeds[aspect]\n",
    "    result = normalize(result, 'l2')\n",
    "    scores = np.dot(result, result.T)\n",
    "    scores[np.arange(len(val_idxs)), np.arange(len(val_idxs))] = -1000\n",
    "    aucs = [0] * len(val_idxs)\n",
    "    for aspect_j in [aspect] :\n",
    "        for i in range(len(val_idxs)) :\n",
    "            aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "        print aspect, aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
