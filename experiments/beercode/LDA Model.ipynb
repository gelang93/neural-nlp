{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import sys\n",
    "sys.path.insert(0, '../../preprocess')\n",
    "import vectorizer\n",
    "beer_data = cPickle.load(open('../../beer_data/beer_vec_ds_df10.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ds = pd.read_csv('../../beer_data/beer_ds.csv')\n",
    "\n",
    "from ast import literal_eval as make_tuple\n",
    "ds['bits'] = ds['bits'].map(lambda s : make_tuple(s))\n",
    "\n",
    "aspect_columns = sorted(['review/appearance', 'review/taste', 'review/aroma', 'review/palate'])\n",
    "\n",
    "train_idxs, val_idxs = train_test_split(ds.index, stratify=ds['bits'], train_size=0.9, random_state=1337)\n",
    "\n",
    "idxs = val_idxs\n",
    "H = {}\n",
    "for i in range(4) :\n",
    "    H[str(i)] = np.zeros((len(idxs), len(idxs)))\n",
    "    a0 = set(ds[ds[aspect_columns[i]] == 0].index) & set(idxs)\n",
    "    a1 = set(ds[ds[aspect_columns[i]] == 1].index) & set(idxs)\n",
    "    a0 = map(lambda s : list(idxs).index(s), a0)\n",
    "    a1 = map(lambda s : list(idxs).index(s), a1)\n",
    "    for j in a0 :\n",
    "        H[str(i)][j, a0] = 1\n",
    "    for j in a1 :\n",
    "        H[str(i)][j, a1] = 1\n",
    "\n",
    "    H[str(i)][np.arange(len(idxs)), np.arange(len(idxs))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = beer_data.X[train_idxs]\n",
    "train_X = map(lambda s : [beer_data.idx2word[t] for t in s if t > 0], train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False)\n",
    "train_TF = tfidf.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_X = beer_data.X[val_idxs]\n",
    "val_X = map(lambda s : [beer_data.idx2word[t] for t in s if t > 0], val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_TF = tfidf.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#embedds_n = normalize(np.array(val_TF.todense()), 'l2')\n",
    "#scores = np.dot(embedds_n, embedds_n.T)\n",
    "scores = cosine_similarity(embedds_n)\n",
    "nb_studies = len(val_idxs)\n",
    "scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.588893125367\n",
      "0 0.597270081065\n",
      "3 0.583869723277\n",
      "2 0.587069684288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "scores = np.array(scores)\n",
    "for aspect_j in H :\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.622527668018\n",
      "0 0.630764199813\n",
      "3 0.615854123934\n",
      "2 0.619540610685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "scores = np.array(scores)\n",
    "for aspect_j in H :\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa = TruncatedSVD(n_components=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lsa = lsa.fit_transform(train_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_lsa = lsa.transform(val_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "embedds_n = normalize(val_lsa, 'l2')\n",
    "scores = np.dot(embedds_n, embedds_n.T)\n",
    "nb_studies = len(val_idxs)\n",
    "scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.588232224084\n",
      "0 0.596819010281\n",
      "3 0.583551483894\n",
      "2 0.586798876777\n"
     ]
    }
   ],
   "source": [
    "#800\n",
    "from sklearn.metrics import roc_auc_score\n",
    "scores = np.array(scores)\n",
    "for aspect_j in H :\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.556527375244\n",
      "0 0.562210688798\n",
      "3 0.55356365904\n",
      "2 0.555587495722\n"
     ]
    }
   ],
   "source": [
    "#200 C\n",
    "from sklearn.metrics import roc_auc_score\n",
    "scores = np.array(scores)\n",
    "for aspect_j in H :\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(tokenizer=lambda i:i, lowercase=False)\n",
    "train_C = count.fit_transform(train_X)\n",
    "val_C = count.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_lda = lda.fit_transform(train_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_lda = lda.transform(val_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "embedds_n = normalize(val_lda, 'l2')\n",
    "scores = np.dot(embedds_n, embedds_n.T)\n",
    "nb_studies = len(val_idxs)\n",
    "scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.697612091001\n",
      "0 0.696654492985\n",
      "3 0.69404681481\n",
      "2 0.695302691346\n"
     ]
    }
   ],
   "source": [
    "#10 LDA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "scores = np.array(scores)\n",
    "for aspect_j in H :\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.688605689378\n",
      "0 0.691113059652\n",
      "3 0.686241107155\n",
      "2 0.687701227426\n"
     ]
    }
   ],
   "source": [
    "#10 LDA 14k\n",
    "from sklearn.metrics import roc_auc_score\n",
    "scores = np.array(scores)\n",
    "for aspect_j in H :\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
