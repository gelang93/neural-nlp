{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import sys\n",
    "sys.path.insert(0, '../../preprocess')\n",
    "import vectorizer\n",
    "beer_data = cPickle.load(open('../../beer_data/beer_vec_ds_df10.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ds = pd.read_csv('../../beer_data/beer_ds.csv')\n",
    "\n",
    "from ast import literal_eval as make_tuple\n",
    "ds['bits'] = ds['bits'].map(lambda s : make_tuple(s))\n",
    "\n",
    "aspect_columns = sorted(['review/appearance', 'review/taste', 'review/aroma', 'review/palate'])\n",
    "\n",
    "train_idxs, val_idxs = train_test_split(ds.index, stratify=ds['bits'], train_size=0.9, random_state=1337)\n",
    "\n",
    "idxs = val_idxs\n",
    "H = {}\n",
    "for i in range(4) :\n",
    "    H[str(i)] = np.zeros((len(idxs), len(idxs)))\n",
    "    a0 = set(ds[ds[aspect_columns[i]] == 0].index) & set(idxs)\n",
    "    a1 = set(ds[ds[aspect_columns[i]] == 1].index) & set(idxs)\n",
    "    a0 = map(lambda s : list(idxs).index(s), a0)\n",
    "    a1 = map(lambda s : list(idxs).index(s), a1)\n",
    "    for j in a0 :\n",
    "        H[str(i)][j, a0] = 1\n",
    "    for j in a1 :\n",
    "        H[str(i)][j, a1] = 1\n",
    "\n",
    "    H[str(i)][np.arange(len(idxs)), np.arange(len(idxs))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = beer_data.X[train_idxs]\n",
    "train_X = map(lambda s : [beer_data.idx2word[t] for t in s if t > 0], train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = beer_data.X[val_idxs]\n",
    "val_X = map(lambda s : [beer_data.idx2word[t] for t in s if t > 0], val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False)\n",
    "train_TF = tfidf.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_TF = tfidf.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "scores = cosine_similarity(embedds_n)\n",
    "nb_studies = len(val_idxs)\n",
    "scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.622527668018\n",
      "0 0.630764199813\n",
      "3 0.615854123934\n",
      "2 0.619540610685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "scores = np.array(scores)\n",
    "for aspect_j in H :\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(tokenizer=lambda i:i, lowercase=False)\n",
    "train_C = count.fit_transform(train_X)\n",
    "val_C = count.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.500170493183\n",
      "2 0.710296810903\n",
      "3 0.766128404167\n",
      "4 0.828780794421\n",
      "5 0.728363162594\n",
      "6 0.733000582207\n",
      "7 0.73845945943\n",
      "8 0.725484990308\n",
      "9 0.715338165464\n",
      "10 0.741679627528\n",
      "11 0.690483753801\n",
      "12 0.739115287582\n",
      "13 0.723561691851\n",
      "14 0.737929461019\n",
      "15 0.707615425239\n",
      "16 0.74659927508\n",
      "17 0.781842536399\n",
      "18 0.709476549801\n",
      "19 0.727780888787\n",
      "20 0.716860596945\n",
      "21 0.751282719178\n",
      "22 0.747910954897\n",
      "23 0.776697087493\n",
      "24 0.652011112945\n",
      "25 0.68041265337\n",
      "26 0.721232803824\n",
      "27 0.730539254943\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#for n_top in range(1, 30) :  \n",
    "n_top = 4\n",
    "lda = LatentDirichletAllocation(n_components=n_top)\n",
    "train_lda = lda.fit_transform(train_C)\n",
    "val_lda = lda.transform(val_C)\n",
    "\n",
    "embedds_n = normalize(val_lda, 'l2')\n",
    "nb_studies = len(val_idxs)\n",
    "scores = np.dot(embedds_n, embedds_n.T)\n",
    "scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000\n",
    "scores = np.array(scores)\n",
    "\n",
    "aucs = [0] * nb_studies\n",
    "for i in range(nb_studies) :\n",
    "    aucs[i] = roc_auc_score(H['0'][i], scores[i])\n",
    "print n_top, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.733605593562\n",
      "0 0.73037470531\n",
      "3 0.728938677461\n",
      "2 0.73031096569\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#for n_top in range(1, 30) :  \n",
    "n_top = 4\n",
    "lda = LatentDirichletAllocation(n_components=n_top, n_jobs=6)\n",
    "train_lda = lda.fit_transform(train_C)\n",
    "val_lda = lda.transform(val_C)\n",
    "\n",
    "embedds_n = normalize(val_lda, 'l2')\n",
    "nb_studies = len(val_idxs)\n",
    "scores = np.dot(embedds_n, embedds_n.T)\n",
    "scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000\n",
    "scores = np.array(scores)\n",
    "\n",
    "for aspect_j in H :\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.699888570535\n",
      "0 0.699681435342\n",
      "3 0.696052804442\n",
      "2 0.696945033317\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#for n_top in range(1, 30) :  \n",
    "n_top = 23\n",
    "lda = LatentDirichletAllocation(n_components=n_top, n_jobs=6)\n",
    "train_lda = lda.fit_transform(train_C)\n",
    "val_lda = lda.transform(val_C)\n",
    "\n",
    "embedds_n = normalize(val_lda, 'l2')\n",
    "nb_studies = len(val_idxs)\n",
    "scores = np.dot(embedds_n, embedds_n.T)\n",
    "scores[np.arange(nb_studies), np.arange(nb_studies)] = -1000\n",
    "scores = np.array(scores)\n",
    "\n",
    "for aspect_j in H :\n",
    "    aucs = [0] * nb_studies\n",
    "    for i in range(nb_studies) :\n",
    "        aucs[i] = roc_auc_score(H[aspect_j][i], scores[i])\n",
    "    print aspect_j, np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = ncount.argsort(axis=1)[:, -40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames=count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taste more just so ... me at ! be had like \t\thave qqq on not one you n't as my 's for but was that in unk and beer is of to a this it , i . the \n",
      "bad \" there qqq thin some much 's yellow smell n't \tin that very but i head this no light taste like : to - beer   unk with not it the of and is \t\ta , . \n",
      "as finish medium beer well aroma taste citrus unk carbonation light sweet good white on that but this hop malt qqq some to in nice   hops head : very - is of with \t\tthe and , a . \n",
      "well good smooth beer taste it malt that on unk alcohol as roasted but black sweet nice this some coffee in qqq   to brown head very chocolate : - dark is with \t\tof the and a , . \n"
     ]
    }
   ],
   "source": [
    "for l in top10 :\n",
    "    for w in l :\n",
    "        print fnames[w],\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6974,  8938, 13267,    82, 13143,  6986,    37,  6560,    55,\n",
       "        13088],\n",
       "       [ 8765,  6986, 13088,  8938,   560,  6974,     1,    82,    37,\n",
       "           55],\n",
       "       [   38,  6974,  8938, 14460,     1, 13088,   560,    37,    82,\n",
       "           55],\n",
       "       [ 3428,  6974, 14460,     1,  8938, 13088,   560,    82,    37,\n",
       "           55]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
